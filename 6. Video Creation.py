# -*- coding: utf-8 -*-
"""Movie Creator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1we6DWPtIIN3Hmmjrapk3hkOgGJ4t7mf5
"""

# 📦 Cell 1 – Install Required Packages
!pip install --quiet moviepy==1.0.3 python-ffmpeg openai pandas tqdm

# 🗃️ Cell 1c – GUI Upload for Assets  ← NEW CELL
from google.colab import files
from pathlib import Path

print("📤 Select your *video_assets.zip* and *narration.wav* (Ctrl‑click to multi‑select):")
uploaded = files.upload()

# Detect files
zip_files   = [f for f in uploaded if f.lower().endswith(".zip")]
audio_files = [f for f in uploaded if f.lower().endswith((".wav", ".mp3", ".m4a"))]

if not zip_files or not audio_files:
    raise ValueError("Please upload at least one .zip and one audio file!")

ASSETS_ZIP = str(Path("/content") / zip_files[0])
AUDIO_WAV  = str(Path("/content") / audio_files[0])

print(f"✅  ZIP   → {ASSETS_ZIP}")
print(f"✅  Audio → {AUDIO_WAV}")

# 📂 Cell 2 – Imports & Path Setup  ← FULL REPLACEMENT
import zipfile, os, json, random
from pathlib import Path
import pandas as pd
from tqdm import tqdm
from moviepy.editor import (
    ImageClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip
)
import openai
from dotenv import load_dotenv
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")  # GPT-guided Ken Burns (optional)
ASSETS_ZIP = globals().get("ASSETS_ZIP", "/content/video_assets.zip")
AUDIO_WAV  = globals().get("AUDIO_WAV",  "/content/narration.wav")

TMP_DIR     = Path("/content/frames")           # extraction folder
CSV_NAME    = "scenes.csv"                      # CSV inside the zip (if nested, Cell 4 will auto‑find)
OUTPUT_MP4  = "/content/final_video.mp4"        # final export
TARGET_SIZE = (1920, 1080)                      # 16:9 canvas (width, height)

# 🗜️ Cell 3 – Extract Assets
if not TMP_DIR.exists():
    TMP_DIR.mkdir(parents=True, exist_ok=True)

with zipfile.ZipFile(ASSETS_ZIP, "r") as z:
    z.extractall(TMP_DIR)

# Sanity‑print a few filenames
print("Extracted examples:", sorted(list(TMP_DIR.glob("scene_*")))[0:5])

# 📝 Cell 4 – Scene CSV Loader (parses bare numbers as seconds)
import re, pandas as pd
from pathlib import Path

def clean(s): return re.sub(r"[^0-9a-z_]", "", s.lower())

csv_path = next(TMP_DIR.rglob("*.csv"), None)
if not csv_path:
    raise FileNotFoundError("No .csv found in extracted ZIP.")
print("📑 Using CSV:", csv_path)

df = pd.read_csv(csv_path)
orig_cols = df.columns.tolist()
df.columns = [clean(c) for c in df.columns]

# locate columns
col_scene  = next((c for c in df if "scene"  in c or "image" in c), None)
col_start  = next((c for c in df if c.startswith("start")), None)
col_end    = next((c for c in df if c.startswith("end")), None)
col_dur    = next((c for c in df if "duration" in c or "length" in c), None)
col_script = next((c for c in df if "script"  in c or "text"  in c), None)

if col_scene is None:
    raise KeyError("Need a scene number column.")
df = df.rename(columns={col_scene: "scene"})
if col_script:
    df = df.rename(columns={col_script: "script"})

def str_to_sec(val):
    """
    Parse a single value to seconds.
    • '00:01:07.5' → 67.5
    • '1:07'       → 67
    • '67.5'       → 67.5
    • '67'         → 67
    """
    s = str(val).strip()
    if ":" in s:                      # timecode
        return pd.to_timedelta(s).total_seconds()
    try:                              # bare number
        return float(s)
    except ValueError:
        return None

def series_to_sec(ser):
    return ser.apply(str_to_sec).astype(float)

# build duration
if col_dur:
    df["duration"] = series_to_sec(df[col_dur])

if "duration" not in df or df["duration"].isna().all():
    if not (col_start and col_end):
        raise ValueError("Need duration or start+end columns.")
    df["start"] = series_to_sec(df[col_start])
    df["end"]   = series_to_sec(df[col_end])
    df["duration"] = df["end"] - df["start"]

# replace any zero/negative durations with 2 s placeholder
df.loc[df["duration"] <= 0, "duration"] = 2.0

df["scene"] = df["scene"].astype(int)
df = df.sort_values("scene").reset_index(drop=True)

print("🧭 Parsed durations (s):")
print(df["duration"].describe())
scenes_df = df

# 🎦 Cell 5 – Ken Burns Helpers (robust JSON + single warning)  ← FULL REPLACEMENT
import re, json, numpy as np

# 👉 Flip off while debugging if you don’t want any GPT traffic
USE_GPT_PANZOOM = True
MODEL = "gpt-4o"        # ← set to a model your key definitely has access to

_warned_once = False     # so we only print the first failure

def random_pan_zoom():
    zoom_start, zoom_end = sorted(
        [random.uniform(1.0, 1.25), random.uniform(1.0, 1.25)], reverse=True
    )
    pan_start = (random.uniform(0.25, 0.75), random.uniform(0.25, 0.75))
    pan_end   = (random.uniform(0.25, 0.75), random.uniform(0.25, 0.75))
    return dict(zoom_start=zoom_start, zoom_end=zoom_end,
                pan_start=pan_start, pan_end=pan_end)

def gpt_pan_zoom(script_segment: str):
    global _warned_once
    if not USE_GPT_PANZOOM or not openai.api_key:
        return random_pan_zoom()

    prompt = (
        "Respond ONLY with valid JSON like "
        '{"zoom_start":1.1,"zoom_end":1.3,"pan_start":[0.4,0.4],"pan_end":[0.6,0.6]}. '
        "No markdown, no extra text.\n"
        "Narration:\n\"\"\"" + script_segment + "\"\"\""
    )
    try:
        resp = openai.chat.completions.create(
            model=MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )
        content = resp.choices[0].message.content.strip()

        # grab first {...} block
        m = re.search(r'\{.*\}', content, re.S)
        if not m:
            raise ValueError("No JSON object found in response:\n" + content[:200])

        data = json.loads(m.group(0))
        return dict(
            zoom_start=float(data["zoom_start"]),
            zoom_end=float(data["zoom_end"]),
            pan_start=tuple(data["pan_start"]),
            pan_end=tuple(data["pan_end"])
        )
    except Exception as e:
        if not _warned_once:
            print("⚠️ GPT pan/zoom failed – falling back to random once.\nReason:", e)
            _warned_once = True
        return random_pan_zoom()

def make_clip(img_path: Path, duration: float, script_segment: str = None):
    fx = gpt_pan_zoom(script_segment)
    base_clip = ImageClip(str(img_path)).set_duration(duration)

    # fit‑cover to 16:9
    tgt_w, tgt_h = TARGET_SIZE
    src_w, src_h = base_clip.size
    scale = max(tgt_w / src_w, tgt_h / src_h)
    base_clip = base_clip.resize(scale)
    base_w, base_h = base_clip.size
    base_frame = base_clip.get_frame(0)

    def kb_frame(_, t):
        prog  = t / duration
        zoom  = fx["zoom_start"] + prog * (fx["zoom_end"] - fx["zoom_start"])
        pan_x = fx["pan_start"][0] + prog * (fx["pan_end"][0] - fx["pan_start"][0])
        pan_y = fx["pan_start"][1] + prog * (fx["pan_end"][1] - fx["pan_start"][1])

        z_h, z_w = int(base_h * zoom), int(base_w * zoom)
        zoomed   = ImageClip(base_frame).resize(zoom).get_frame(0)

        crop_x = int(np.clip(pan_x * z_w - tgt_w / 2, 0, z_w - tgt_w))
        crop_y = int(np.clip(pan_y * z_h - tgt_h / 2, 0, z_h - tgt_h))
        return zoomed[crop_y:crop_y + tgt_h, crop_x:crop_x + tgt_w]

    return base_clip.fl(kb_frame, apply_to=["mask"]).set_duration(duration)

# 🏗️ Cell 6 – Assemble Video Clips  (Freeze‑Frame Padding)
video_clips = []
for _, row in tqdm(scenes_df.iterrows(), total=len(scenes_df)):
    img_pattern = f"scene_{row.scene:03d}.*"
    img_path = next(TMP_DIR.rglob(img_pattern), None)
    if img_path is None:
        raise FileNotFoundError(f"Missing image for {img_pattern}")
    clip = make_clip(img_path, row.duration, row.get("script", ""))
    video_clips.append(clip)

# --- Build initial video ---
full_video = concatenate_videoclips(video_clips, method="compose")

# --- Pad with last frame if audio is longer ---
audio = AudioFileClip(AUDIO_WAV)
gap = audio.duration - full_video.duration
if gap > 0.05:                                 # pad if > 50 ms difference
    print(f"📏 Audio is longer by {gap:0.2f} s – adding freeze‑frame padding")
    last_clip   = video_clips[-1]
    freeze_clip = last_clip.fx(vfx.freeze,
                               t=last_clip.duration,
                               freeze_duration=gap)
    full_video  = concatenate_videoclips([full_video, freeze_clip],
                                         method="compose")
else:
    print("✅ Video already matches or exceeds audio length")

# hand off to later cells

# 🔊 Cell 7 – Add Audio, Sanity‑Check Durations, Export   ← REPLACE old Cell 7
from math import isclose

audio = AudioFileClip(AUDIO_WAV)

# ── Print original durations ────────────────────────────
vid_dur  = full_video.duration or 0
aud_dur  = audio.duration or 0
print(f"🎥  Video length : {vid_dur:0.3f} s")
print(f"🎧  Audio length : {aud_dur:0.3f} s")

# ── Choose a safe synced duration ───────────────────────
#  * If the tracks differ by ≤ 50 ms we treat them as “equal”
#  * Otherwise we cut both to the shorter one
tol = 0.05                                   # 50 ms tolerance
if isclose(vid_dur, aud_dur, abs_tol=tol):
    target_dur = min(vid_dur, aud_dur)
else:
    target_dur = min(vid_dur, aud_dur)

# nip 10 ms off the end so MoviePy never asks for the
# final sample that might not exist
target_dur = max(target_dur - 0.01, 0)

if target_dur <= 0:
    raise ValueError(
        "❌ Calculated duration is 0 s. Check that your scene CSV produced "
        "non‑zero video clips and that the audio file isn’t empty."
    )

print(f"⏱️  Synced length  : {target_dur:0.3f} s")

full_video = full_video.subclip(0, target_dur)
audio      = audio.subclip(0, target_dur)
full_video = full_video.set_audio(audio)

# ── Export ──────────────────────────────────────────────
full_video.write_videofile(
    OUTPUT_MP4,
    codec="libx264",
    audio_codec="aac",
    fps=30,
    preset="medium",
    threads=4,
    verbose=True
)

# 🎉 Cell 8 – Preview & Reliable Download   ← REPLACE old Cell 8
import os, base64, math
from google.colab import files
from IPython.display import HTML, display
from moviepy.editor import VideoFileClip

file_size = os.path.getsize(OUTPUT_MP4)
print(f"📦 final_video.mp4 size: {file_size/1_000_000:.2f} MB")

# Quick sanity check: open the file and print duration
try:
    tmp_clip = VideoFileClip(OUTPUT_MP4)
    print(f"✅ File opens fine, duration = {tmp_clip.duration:0.2f}s")
    tmp_clip.close()
except Exception as e:
    print("⚠️ Couldn’t reopen the video:", e)

# Try in‑notebook video preview (works for most files < ~150 MB)
try:
    display(HTML(f'<video src="{OUTPUT_MP4}" width="640" controls></video>'))
except Exception as e:
    print("Inline preview failed:", e)

# Fallback: force a download to your local machine
print("⬇️  Click the link below if the inline preview is blank or download fails:")
files.download(OUTPUT_MP4)