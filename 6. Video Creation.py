# -*- coding: utf-8 -*-
"""Movie Creator.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1we6DWPtIIN3Hmmjrapk3hkOgGJ4t7mf5
"""

# ğŸ“¦ Cellâ€¯1Â â€“Â Install Required Packages
!pip install --quiet moviepy==1.0.3 python-ffmpeg openai pandas tqdm

# ğŸ—ƒï¸ Cellâ€¯1cÂ â€“Â GUI Upload for Assets  â†Â NEW CELL
from google.colab import files
from pathlib import Path

print("ğŸ“¤ Select your *video_assets.zip* and *narration.wav* (Ctrlâ€‘click to multiâ€‘select):")
uploaded = files.upload()

# Detect files
zip_files   = [f for f in uploaded if f.lower().endswith(".zip")]
audio_files = [f for f in uploaded if f.lower().endswith((".wav", ".mp3", ".m4a"))]

if not zip_files or not audio_files:
    raise ValueError("Please upload at least one .zip and one audio file!")

ASSETS_ZIP = str(Path("/content") / zip_files[0])
AUDIO_WAV  = str(Path("/content") / audio_files[0])

print(f"âœ…  ZIP   â†’ {ASSETS_ZIP}")
print(f"âœ…  Audio â†’ {AUDIO_WAV}")

# ğŸ“‚ Cellâ€¯2Â â€“Â Imports & Path Setup Â â†Â FULL REPLACEMENT
import zipfile, os, json, random
from pathlib import Path
import pandas as pd
from tqdm import tqdm
from moviepy.editor import (
    ImageClip, AudioFileClip, concatenate_videoclips, CompositeVideoClip
)
import openai
from dotenv import load_dotenv
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")  # GPT-guided Ken Burns (optional)
ASSETS_ZIP = globals().get("ASSETS_ZIP", "/content/video_assets.zip")
AUDIO_WAV  = globals().get("AUDIO_WAV",  "/content/narration.wav")

TMP_DIR     = Path("/content/frames")           # extraction folder
CSV_NAME    = "scenes.csv"                      # CSV inside the zip (if nested, Cellâ€¯4 will autoâ€‘find)
OUTPUT_MP4  = "/content/final_video.mp4"        # final export
TARGET_SIZE = (1920, 1080)                      # 16:9 canvas (width, height)

# ğŸ—œï¸ Cellâ€¯3Â â€“Â Extract Assets
if not TMP_DIR.exists():
    TMP_DIR.mkdir(parents=True, exist_ok=True)

with zipfile.ZipFile(ASSETS_ZIP, "r") as z:
    z.extractall(TMP_DIR)

# Sanityâ€‘print a few filenames
print("Extracted examples:", sorted(list(TMP_DIR.glob("scene_*")))[0:5])

# ğŸ“ Cellâ€¯4Â â€“Â Scene CSV Loader (parses bare numbers as seconds)
import re, pandas as pd
from pathlib import Path

def clean(s): return re.sub(r"[^0-9a-z_]", "", s.lower())

csv_path = next(TMP_DIR.rglob("*.csv"), None)
if not csv_path:
    raise FileNotFoundError("No .csv found in extracted ZIP.")
print("ğŸ“‘ Using CSV:", csv_path)

df = pd.read_csv(csv_path)
orig_cols = df.columns.tolist()
df.columns = [clean(c) for c in df.columns]

# locate columns
col_scene  = next((c for c in df if "scene"  in c or "image" in c), None)
col_start  = next((c for c in df if c.startswith("start")), None)
col_end    = next((c for c in df if c.startswith("end")), None)
col_dur    = next((c for c in df if "duration" in c or "length" in c), None)
col_script = next((c for c in df if "script"  in c or "text"  in c), None)

if col_scene is None:
    raise KeyError("Need a scene number column.")
df = df.rename(columns={col_scene: "scene"})
if col_script:
    df = df.rename(columns={col_script: "script"})

def str_to_sec(val):
    """
    Parse a single value to seconds.
    â€¢ '00:01:07.5' â†’ 67.5
    â€¢ '1:07'       â†’ 67
    â€¢ '67.5'       â†’ 67.5
    â€¢ '67'         â†’ 67
    """
    s = str(val).strip()
    if ":" in s:                      # timecode
        return pd.to_timedelta(s).total_seconds()
    try:                              # bare number
        return float(s)
    except ValueError:
        return None

def series_to_sec(ser):
    return ser.apply(str_to_sec).astype(float)

# build duration
if col_dur:
    df["duration"] = series_to_sec(df[col_dur])

if "duration" not in df or df["duration"].isna().all():
    if not (col_start and col_end):
        raise ValueError("Need duration or start+end columns.")
    df["start"] = series_to_sec(df[col_start])
    df["end"]   = series_to_sec(df[col_end])
    df["duration"] = df["end"] - df["start"]

# replace any zero/negative durations with 2â€¯s placeholder
df.loc[df["duration"] <= 0, "duration"] = 2.0

df["scene"] = df["scene"].astype(int)
df = df.sort_values("scene").reset_index(drop=True)

print("ğŸ§­ Parsed durations (s):")
print(df["duration"].describe())
scenes_df = df

# ğŸ¦ Cellâ€¯5Â â€“Â KenÂ BurnsÂ Helpers (robust JSON + single warning)  â†Â FULL REPLACEMENT
import re, json, numpy as np

# ğŸ‘‰ Flip off while debugging if you donâ€™t want any GPT traffic
USE_GPT_PANZOOM = True
MODEL = "gpt-4o"        # â† set to a model your key definitely has access to

_warned_once = False     # so we only print the first failure

def random_pan_zoom():
    zoom_start, zoom_end = sorted(
        [random.uniform(1.0, 1.25), random.uniform(1.0, 1.25)], reverse=True
    )
    pan_start = (random.uniform(0.25, 0.75), random.uniform(0.25, 0.75))
    pan_end   = (random.uniform(0.25, 0.75), random.uniform(0.25, 0.75))
    return dict(zoom_start=zoom_start, zoom_end=zoom_end,
                pan_start=pan_start, pan_end=pan_end)

def gpt_pan_zoom(script_segment: str):
    global _warned_once
    if not USE_GPT_PANZOOM or not openai.api_key:
        return random_pan_zoom()

    prompt = (
        "Respond ONLY with valid JSON like "
        '{"zoom_start":1.1,"zoom_end":1.3,"pan_start":[0.4,0.4],"pan_end":[0.6,0.6]}. '
        "No markdown, no extra text.\n"
        "Narration:\n\"\"\"" + script_segment + "\"\"\""
    )
    try:
        resp = openai.chat.completions.create(
            model=MODEL,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
        )
        content = resp.choices[0].message.content.strip()

        # grab first {...} block
        m = re.search(r'\{.*\}', content, re.S)
        if not m:
            raise ValueError("No JSON object found in response:\n" + content[:200])

        data = json.loads(m.group(0))
        return dict(
            zoom_start=float(data["zoom_start"]),
            zoom_end=float(data["zoom_end"]),
            pan_start=tuple(data["pan_start"]),
            pan_end=tuple(data["pan_end"])
        )
    except Exception as e:
        if not _warned_once:
            print("âš ï¸ GPT pan/zoom failed â€“ falling back to random once.\nReason:", e)
            _warned_once = True
        return random_pan_zoom()

def make_clip(img_path: Path, duration: float, script_segment: str = None):
    fx = gpt_pan_zoom(script_segment)
    base_clip = ImageClip(str(img_path)).set_duration(duration)

    # fitâ€‘cover to 16:9
    tgt_w, tgt_h = TARGET_SIZE
    src_w, src_h = base_clip.size
    scale = max(tgt_w / src_w, tgt_h / src_h)
    base_clip = base_clip.resize(scale)
    base_w, base_h = base_clip.size
    base_frame = base_clip.get_frame(0)

    def kb_frame(_, t):
        prog  = t / duration
        zoom  = fx["zoom_start"] + prog * (fx["zoom_end"] - fx["zoom_start"])
        pan_x = fx["pan_start"][0] + prog * (fx["pan_end"][0] - fx["pan_start"][0])
        pan_y = fx["pan_start"][1] + prog * (fx["pan_end"][1] - fx["pan_start"][1])

        z_h, z_w = int(base_h * zoom), int(base_w * zoom)
        zoomed   = ImageClip(base_frame).resize(zoom).get_frame(0)

        crop_x = int(np.clip(pan_x * z_w - tgt_w / 2, 0, z_w - tgt_w))
        crop_y = int(np.clip(pan_y * z_h - tgt_h / 2, 0, z_h - tgt_h))
        return zoomed[crop_y:crop_y + tgt_h, crop_x:crop_x + tgt_w]

    return base_clip.fl(kb_frame, apply_to=["mask"]).set_duration(duration)

# ğŸ—ï¸ Cellâ€¯6Â â€“Â Assemble Video Clips  (Freezeâ€‘Frame Padding)
video_clips = []
for _, row in tqdm(scenes_df.iterrows(), total=len(scenes_df)):
    img_pattern = f"scene_{row.scene:03d}.*"
    img_path = next(TMP_DIR.rglob(img_pattern), None)
    if img_path is None:
        raise FileNotFoundError(f"Missing image for {img_pattern}")
    clip = make_clip(img_path, row.duration, row.get("script", ""))
    video_clips.append(clip)

# --- Build initial video ---
full_video = concatenate_videoclips(video_clips, method="compose")

# --- Pad with last frame if audio is longer ---
audio = AudioFileClip(AUDIO_WAV)
gap = audio.duration - full_video.duration
if gap > 0.05:                                 # pad if > 50â€¯ms difference
    print(f"ğŸ“ Audio is longer by {gap:0.2f}â€¯s â€“ adding freezeâ€‘frame padding")
    last_clip   = video_clips[-1]
    freeze_clip = last_clip.fx(vfx.freeze,
                               t=last_clip.duration,
                               freeze_duration=gap)
    full_video  = concatenate_videoclips([full_video, freeze_clip],
                                         method="compose")
else:
    print("âœ… Video already matches or exceeds audio length")

# hand off to later cells

# ğŸ”Š Cellâ€¯7Â â€“Â Add Audio, Sanityâ€‘Check Durations, Export   â† REPLACE old Cellâ€¯7
from math import isclose

audio = AudioFileClip(AUDIO_WAV)

# â”€â”€ Print original durations â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
vid_dur  = full_video.duration or 0
aud_dur  = audio.duration or 0
print(f"ğŸ¥  Video length : {vid_dur:0.3f}â€¯s")
print(f"ğŸ§  Audio length : {aud_dur:0.3f}â€¯s")

# â”€â”€ Choose a safe synced duration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
#  * If the tracks differ by â‰¤Â 50â€¯ms we treat them as â€œequalâ€
#  * Otherwise we cut both to the shorter one
tol = 0.05                                   # 50â€¯ms tolerance
if isclose(vid_dur, aud_dur, abs_tol=tol):
    target_dur = min(vid_dur, aud_dur)
else:
    target_dur = min(vid_dur, aud_dur)

# nip 10â€¯ms off the end so MoviePy never asks for the
# final sample that might not exist
target_dur = max(target_dur - 0.01, 0)

if target_dur <= 0:
    raise ValueError(
        "âŒ Calculated duration is 0â€¯s. Check that your scene CSV produced "
        "nonâ€‘zero video clips and that the audio file isnâ€™t empty."
    )

print(f"â±ï¸  Synced length  : {target_dur:0.3f}â€¯s")

full_video = full_video.subclip(0, target_dur)
audio      = audio.subclip(0, target_dur)
full_video = full_video.set_audio(audio)

# â”€â”€ Export â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
full_video.write_videofile(
    OUTPUT_MP4,
    codec="libx264",
    audio_codec="aac",
    fps=30,
    preset="medium",
    threads=4,
    verbose=True
)

# ğŸ‰ Cellâ€¯8Â â€“Â Preview & Reliable Download   â†Â REPLACE old Cellâ€¯8
import os, base64, math
from google.colab import files
from IPython.display import HTML, display
from moviepy.editor import VideoFileClip

file_size = os.path.getsize(OUTPUT_MP4)
print(f"ğŸ“¦ final_video.mp4 size: {file_size/1_000_000:.2f}â€¯MB")

# Quick sanity check: open the file and print duration
try:
    tmp_clip = VideoFileClip(OUTPUT_MP4)
    print(f"âœ… File opens fine, duration = {tmp_clip.duration:0.2f}s")
    tmp_clip.close()
except Exception as e:
    print("âš ï¸ Couldnâ€™t reopen the video:", e)

# Try inâ€‘notebook video preview (works for most files < ~150â€¯MB)
try:
    display(HTML(f'<video src="{OUTPUT_MP4}" width="640" controls></video>'))
except Exception as e:
    print("Inline preview failed:", e)

# Fallback: force a download to your local machine
print("â¬‡ï¸  Click the link below if the inline preview is blank or download fails:")
files.download(OUTPUT_MP4)